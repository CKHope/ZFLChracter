{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea68ffc-7b63-4b2c-a47e-edbe955e5d64",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50aae868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chineseTextLib import *\n",
    "from chineseDict import *\n",
    "import os\n",
    "import json\n",
    "from pyvis.network import Network\n",
    "from helper import timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc1274",
   "metadata": {},
   "source": [
    "## Create character & word dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996faf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Admin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.682 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traditionalChinese</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我們</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>這個</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>修煉</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  traditionalChinese  times\n",
       "0                 我們    880\n",
       "1                 這個    766\n",
       "2                 修煉    686"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName=\"zfl\"\n",
    "baseInputLink = f\"./zfl/wordCountInput/{fileName}.txt\"\n",
    "dfWords=createWordListFromText(baseInputLink)\n",
    "dfKnownWords=createCharacterListFromText(baseInputLink)\n",
    "# dfknownWords\n",
    "dfWords[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c92ce",
   "metadata": {},
   "source": [
    "## Slice word list for scraping data online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82629358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  traditionalChinese  times  content\n",
      "0                 我們    880      NaN\n"
     ]
    }
   ],
   "source": [
    "#create conent column with NaN value\n",
    "dfWords2Process=dfWords\n",
    "dfWords2Process['content']=np.nan\n",
    "print(dfWords2Process.head(1))\n",
    "\n",
    "#create slice of charSet then save to picle file type\n",
    "list=np.arange(0,len(dfWords),100)\n",
    "list=np.append(list,len(dfWords))\n",
    "# print(list)\n",
    "i=0\n",
    "for i in range(len(list)-1):\n",
    "    if os.path.exists(f\"./data/charSet/charSet {i:02d}-{list[i]}-{list[i+1]}.pkl\"):\n",
    "        pass\n",
    "        # print(\"Already slice. Go ahead\")\n",
    "    else:\n",
    "        dfWords2ProcessSlice=dfWords2Process[list[i]:list[i+1]]\n",
    "        dfWords2ProcessSlice.to_pickle(f\"./data/charSet/charSet {i:02d}-{list[i]}-{list[i+1]}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8353c4",
   "metadata": {},
   "source": [
    "## Get data for each slide then save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc5899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get phrase content for each slices of charSet\n",
    "# currentFolderPath = os.getcwd()\n",
    "# folder2Process=f\"{currentFolderPath}/data/charSet\"\n",
    "# for root, directories, files in os.walk(folder2Process):\n",
    "#     #loop through files\n",
    "#     for f in files:\n",
    "#         if os.path.exists(f\"{folder2Process}/output/{f}\")==True:\n",
    "#             pass\n",
    "#             print(f\"already existed: {folder2Process}/ouput/{f}\")\n",
    "#         else:\n",
    "#             print(\"Start craw new datas\")\n",
    "#             dfTemp2PrcessCharSet=pd.read_pickle(f\"{folder2Process}/{f}\")\n",
    "#             print(f\"Processing {folder2Process}/{f}\")\n",
    "#             #loop through dataFrame rows\n",
    "#             for index,row in dfTemp2PrcessCharSet.iterrows(): \n",
    "#                 #check to get phrase content if null\n",
    "#                 if pd.isnull(row['content']):\n",
    "#                     # print(row['traditionalChinese'])\n",
    "#                     content=getPhraseContent(row['traditionalChinese'])\n",
    "#                     dfTemp2PrcessCharSet.at[index,'content']=content\n",
    "#             dfTemp2PrcessCharSet.to_pickle(f\"{folder2Process}/output/{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d52c6",
   "metadata": {},
   "source": [
    "## Create word detail column for node lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcb2525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>percentile</th>\n",
       "      <th>traChinese</th>\n",
       "      <th>simChinese</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>zhuyin</th>\n",
       "      <th>chineseDetails</th>\n",
       "      <th>englishDetails</th>\n",
       "      <th>vietnameseDetails</th>\n",
       "      <th>wordDetails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880</td>\n",
       "      <td>100.0</td>\n",
       "      <td>我們</td>\n",
       "      <td>我们</td>\n",
       "      <td>wǒ men</td>\n",
       "      <td>ㄨㄛˇ ㄇㄣ</td>\n",
       "      <td>(1).稱包括本身在內的若干人。《紅樓夢·第四三回》：「我們不敢和老太太並肩，自然矮一等。」...</td>\n",
       "      <td>---(E)we, us, ourselves, our</td>\n",
       "      <td>---(V)1. chúng tôi; chúng ta; chúng tao; chúng...</td>\n",
       "      <td>\\nwǒ men | ㄨㄛˇ ㄇㄣ\\n我們 | 我们 -- 880\\n---(V)1. ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times  percentile traChinese simChinese  pinyin  zhuyin  \\\n",
       "0    880       100.0         我們         我们  wǒ men  ㄨㄛˇ ㄇㄣ   \n",
       "\n",
       "                                      chineseDetails  \\\n",
       "0  (1).稱包括本身在內的若干人。《紅樓夢·第四三回》：「我們不敢和老太太並肩，自然矮一等。」...   \n",
       "\n",
       "                 englishDetails  \\\n",
       "0  ---(E)we, us, ourselves, our   \n",
       "\n",
       "                                   vietnameseDetails  \\\n",
       "0  ---(V)1. chúng tôi; chúng ta; chúng tao; chúng...   \n",
       "\n",
       "                                         wordDetails  \n",
       "0  \\nwǒ men | ㄨㄛˇ ㄇㄣ\\n我們 | 我们 -- 880\\n---(V)1. ch...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfallCharSet=pd.read_pickle(\"./data/charSet/output/allCharSet.pkl\")\n",
    "dfallCharSet=dfallCharSet[dfallCharSet.chineseDetails!=\"\"]\n",
    "dfallCharSet['wordDetails']=dfallCharSet.apply(lambda x:f\"\"\"\n",
    "{x.pinyin} | {x.zhuyin}\n",
    "{x.traChinese} | {x.simChinese} -- {x.times}\n",
    "{x.vietnameseDetails}\n",
    "{x.chineseDetails}\n",
    "{x.englishDetails}\"\"\", axis = 1)\n",
    "dfallCharSet[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f070562",
   "metadata": {},
   "source": [
    "## Prepare Unihan dict data for lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f15464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>definition</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>radical</th>\n",
       "      <th>type</th>\n",
       "      <th>hint</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⺀</td>\n",
       "      <td>ice</td>\n",
       "      <td>[]</td>\n",
       "      <td>？</td>\n",
       "      <td>⺀</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character definition pinyin decomposition radical type hint phonetic  \\\n",
       "0         ⺀        ice     []             ？       ⺀  NaN  NaN      NaN   \n",
       "\n",
       "  semantic  \n",
       "0      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unihanDict=convertTxtData2Dict(txtObject=\"dictionary.txt\")\n",
    "print(len(unihanDict))\n",
    "\n",
    "#convert to list of dict\n",
    "unihanDictList=[]\n",
    "for value in unihanDict.values():\n",
    "    jsonValue=json.loads(value)\n",
    "    unihanDictList.append(jsonValue)\n",
    "\n",
    "indexRange=np.arange(0,len(unihanDict))\n",
    "dfUnihanDict=pd.DataFrame(unihanDictList,index=indexRange)\n",
    "#Convert etymology dict-column to columns; then remove it and matches\n",
    "dfUnihanDict=(dfUnihanDict\n",
    "                    .join(pd.json_normalize(dfUnihanDict.pop('etymology')))\n",
    "                    .drop('matches',axis=1)\n",
    "                )\n",
    "\n",
    "saveDict2JSON(unihanDictList,\"hanziDictList.json\")\n",
    "dfUnihanDict[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867850c",
   "metadata": {},
   "source": [
    "## Merge Character df and dfUnihanDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a26ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>character</th>\n",
       "      <th>definition</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>radical</th>\n",
       "      <th>type</th>\n",
       "      <th>hint</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>semantic</th>\n",
       "      <th>percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7236</td>\n",
       "      <td>的</td>\n",
       "      <td>aim, goal; of; possessive particle; -self suffix</td>\n",
       "      <td>[de]</td>\n",
       "      <td>⿰白勺</td>\n",
       "      <td>白</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times character                                        definition pinyin  \\\n",
       "0   7236         的  aim, goal; of; possessive particle; -self suffix   [de]   \n",
       "\n",
       "  decomposition radical type hint phonetic semantic  percentile  \n",
       "0           ⿰白勺       白  NaN  NaN      NaN      NaN       100.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCharacter=dfKnownWords.merge(dfUnihanDict,left_on=\"word\",right_on=\"character\")\n",
    "dfCharacter=dfCharacter.drop(['word'],axis=1)\n",
    "dfCharacter[:1]\n",
    "dfCharacter['percentile']=np.flip(np.arange(1,len(dfCharacter)+1)/len(dfCharacter)*100)\n",
    "\n",
    "dictCharacter=dfCharacter.to_dict()\n",
    "print(len(dictCharacter['character']))\n",
    "dfCharacter[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708b571",
   "metadata": {},
   "source": [
    "## Create character detail column for node lookup and save to characterDataZFL.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac52d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created. Go ahead!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>character</th>\n",
       "      <th>definition</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>radical</th>\n",
       "      <th>type</th>\n",
       "      <th>hint</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>semantic</th>\n",
       "      <th>percentile</th>\n",
       "      <th>words</th>\n",
       "      <th>characterDetails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7236</td>\n",
       "      <td>的</td>\n",
       "      <td>aim, goal; of; possessive particle; -self suffix</td>\n",
       "      <td>[de]</td>\n",
       "      <td>⿰白勺</td>\n",
       "      <td>白</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[目的, 似的, 有的是, 重重的]</td>\n",
       "      <td>\\n    ['de'] | ⿰白勺 -- 7236\\n    nan | sound:na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times character                                        definition pinyin  \\\n",
       "0   7236         的  aim, goal; of; possessive particle; -self suffix   [de]   \n",
       "\n",
       "  decomposition radical type hint phonetic semantic  percentile  \\\n",
       "0           ⿰白勺       白  NaN  NaN      NaN      NaN       100.0   \n",
       "\n",
       "                words                                   characterDetails  \n",
       "0  [目的, 似的, 有的是, 重重的]  \\n    ['de'] | ⿰白勺 -- 7236\\n    nan | sound:na...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(\"characterDataZFL.pkl\"): # Or folder, will return true or false:\n",
    "    print(\"File created. Go ahead!\")\n",
    "    dfCharacter=pd.read_pickle('characterDataZFL.pkl')\n",
    "else:\n",
    "    dataFrameColumn=dfallCharSet['traChinese']\n",
    "    dfCharacter['words'] = dfCharacter['character'].map(lambda x: relatedWordsZFL(x,dataFrameColumn))\n",
    "    \n",
    "    #combine character details\n",
    "    dfCharacter['characterDetails']=dfCharacter.apply(lambda x:f\"\"\"\n",
    "    {x.pinyin} | {x.decomposition} -- {x.times}\n",
    "    {x.type} | sound:{x.phonetic} -- mean: {x.semantic}\n",
    "    hint -- {x.hint}\n",
    "    meaning -- {x.definition}\n",
    "    words -- {x.words}\"\"\", axis = 1)\n",
    "    \n",
    "    # Save to pickle\n",
    "    dfCharacter.to_pickle('characterDataZFL.pkl')\n",
    "dfCharacter[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f790f-20fa-4b2f-878b-e258c07be57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0a24b6",
   "metadata": {},
   "source": [
    "## Set network options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b29498",
   "metadata": {},
   "outputs": [],
   "source": [
    "options=\"\"\"\n",
    "const options = {\n",
    "  \"nodes\": {\n",
    "    \"borderWidth\": 0,\n",
    "    \"borderWidthSelected\": 5,\n",
    "    \"opacity\": 0.8,\n",
    "    \"labelHighlightBold\": false,\n",
    "    \"shadow\": {\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    \"shape\": \"circle\",\n",
    "    \"title\":{\n",
    "      \"multi\": \"html\",\n",
    "      \"color\":\"white\",\n",
    "      \"size\":24,\n",
    "      \"font\": {\n",
    "        \"size\": 24\n",
    "    }\n",
    "    },\n",
    "    \"size\": null,\n",
    "    \"font\": {\n",
    "      \"size\": 24\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\n",
    "      \"inherit\": true\n",
    "    },\n",
    "    \"labelHighlightBold\": false,\n",
    "    \"selfReferenceSize\": null,\n",
    "    \"selfReference\": {\n",
    "      \"angle\": 0.7853981633974483\n",
    "    },\n",
    "    \"smooth\": {\n",
    "      \"type\": \"diagonalCross\",\n",
    "      \"forceDirection\": \"none\"\n",
    "    },\n",
    "    \"width\":0\n",
    "  },\n",
    "  \"interaction\": {\n",
    "    \"navigationButtons\": true,\n",
    "    \"tooltipDelay\": 50,\n",
    "    \"zoomSpeed\": 5\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"repulsion\": {\n",
    "      \"nodeDistance\": 300,\n",
    "      \"central_gravity\":0.8,\n",
    "      \"springLength\": 50,\n",
    "      \"spring_strength\":0.05,\n",
    "      \"damping\":0.08\n",
    "    },\n",
    "    \"maxVelocity\": 50,\n",
    "    \"minVelocity\": 5,\n",
    "    \"solver\": \"repulsion\"\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0651282",
   "metadata": {},
   "source": [
    "## Prepare final dictCharacter for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17927df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>character</th>\n",
       "      <th>definition</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>radical</th>\n",
       "      <th>type</th>\n",
       "      <th>hint</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>semantic</th>\n",
       "      <th>percentile</th>\n",
       "      <th>words</th>\n",
       "      <th>characterDetails</th>\n",
       "      <th>wordDetails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7236</td>\n",
       "      <td>的</td>\n",
       "      <td>aim, goal; of; possessive particle; -self suffix</td>\n",
       "      <td>[de]</td>\n",
       "      <td>⿰白勺</td>\n",
       "      <td>白</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[目的, 似的, 有的是, 重重的]</td>\n",
       "      <td>\\n    ['de'] | ⿰白勺 -- 7236\\n    nan | sound:na...</td>\n",
       "      <td>[\\nmù dì | ㄇㄨˋ ㄉㄧˋ\\n目的 | 目的 -- 17\\n---(V)1. mụ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times character                                        definition pinyin  \\\n",
       "0   7236         的  aim, goal; of; possessive particle; -self suffix   [de]   \n",
       "\n",
       "  decomposition radical type hint phonetic semantic  percentile  \\\n",
       "0           ⿰白勺       白  NaN  NaN      NaN      NaN       100.0   \n",
       "\n",
       "                words                                   characterDetails  \\\n",
       "0  [目的, 似的, 有的是, 重重的]  \\n    ['de'] | ⿰白勺 -- 7236\\n    nan | sound:na...   \n",
       "\n",
       "                                         wordDetails  \n",
       "0  [\\nmù dì | ㄇㄨˋ ㄉㄧˋ\\n目的 | 目的 -- 17\\n---(V)1. mụ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictCharacter=pd.read_pickle(\"characterDataZFL.pkl\")\n",
    "\n",
    "@timer\n",
    "def updateWordDetails(listOfWords,df):\n",
    "    tempWordDetailList=[]\n",
    "    for i in range(len(listOfWords)):\n",
    "        wordDetail=getWordContent(listOfWords[i],df)\n",
    "        tempWordDetailList.append(wordDetail)\n",
    "    return tempWordDetailList\n",
    "\n",
    "if os.path.exists(\"dfCharacterZFL.pkl\"):\n",
    "    dictCharacter=pd.read_pickle(\"dfCharacterZFL.pkl\")\n",
    "    pass\n",
    "else:\n",
    "    dictCharacter['wordDetails']=dictCharacter['words'].map(lambda x: updateWordDetails(x,dfallCharSet))\n",
    "    dictCharacter.to_pickle(\"dfCharacterZFL.pkl\")\n",
    "dictCharacter[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f4256",
   "metadata": {},
   "source": [
    "## Generate NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ccff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "['扌', '口', '氵', '亻', '木言', '辶⺼土', '艹糹心女', '阝宀日釒忄', '石刂目⺮火足車', '貝禾彳頁广王攵力', '田疒大犭門一囗穴米儿巾', '虫耳酉寸止礻十隹子飠雨戈手欠糸']\n"
     ]
    }
   ],
   "source": [
    "def map_data(characterData,shape='circle',radColor=\"#ece6d0\",bgColor=\"#222222\"):\n",
    "    g=Network(notebook=True,height='900px',width=\"100%\",bgcolor=bgColor,font_color=\"black\",\n",
    "              select_menu=False,neighborhood_highlight=True,filter_menu=True,cdn_resources=\"in_line\")\n",
    "    for node in characterData:\n",
    "        if node['times']==1:\n",
    "            node['color']=\"#ffffff\"\n",
    "            node['group']=4\n",
    "        else:\n",
    "            result=getColorBasedOnPercentile(node['percentile'])\n",
    "            node['color']=result[0]\n",
    "            node['group']=result[1]\n",
    "    order=1\n",
    "    for list in listOfRadList:\n",
    "        # print(list)\n",
    "        for node in characterData:\n",
    "            if node['radical'] in list:\n",
    "                g.add_node(node['character'],shape=shape,color=node['color'],title=node['characterDetails'])\n",
    "                g.add_node(node['radical'],shape=shape,color=radColor)\n",
    "                g.add_edge(node['radical'],node['character'],color=node['color'])\n",
    "                for i in range(len(node['words'])):\n",
    "                    g.add_node(node['words'][i],shape=\"box\",color=\"white\",title=node['wordDetails'][i])\n",
    "                    g.add_edge(node['character'],node['words'][i],color=node['color'])\n",
    "        # g.repulsion(node_distance=80,central_gravity=0.2,spring_length=50,spring_strength=0.05,damping=0.09)\n",
    "        # g.set_edge_smooth('diagonalCross')\n",
    "        # g.show_buttons(True)\n",
    "        g.set_options(options)\n",
    "        g.prep_notebook()\n",
    "        g.show(f\"N{order}--{list}.html\",local=True)\n",
    "        #reset network\n",
    "        g=Network(notebook=True,height='900px',width=\"100%\",bgcolor=bgColor,font_color='black',\n",
    "              select_menu=False,neighborhood_highlight=True,filter_menu=False,cdn_resources=\"in_line\")\n",
    "        order+=1\n",
    "\n",
    "#Slice list of radical to make each html file get x nodes\n",
    "# listOfRadList=sliceRadicalListFromDf(dfKradical,np.ceil(len(dfKradical)/2))\n",
    "listOfRadList=sliceRadicalListFromDf(dfCharacter,150)\n",
    "\n",
    "dictCharacter=pd.read_pickle(\"dfCharacterZFL.pkl\")\n",
    "# dfTest=pd.DataFrame(dictCharacter[:300]['words']).to_pickle(\"testData.pkl\")\n",
    "columns2keep=['character','percentile','words','characterDetails','wordDetails','times','radical']\n",
    "dictCharacter=dictCharacter[columns2keep]\n",
    "dictCharacter=dictCharacter.to_dict('records')\n",
    "# dictCharacter[:10]\n",
    "map_data(dictCharacter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "72b2382ece9768098284d92bbc69d35954e75b60d1e25897d1389c232f4796f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
